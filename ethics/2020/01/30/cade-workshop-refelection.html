<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Tech Policy Workshop and Data Ethics | Asymptote</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Tech Policy Workshop and Data Ethics" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I participated a two-day workshop on tech ethics and policy at USF. The speakers and attendees were from a variety of disciplines ranging from tech to non-profit, law, and government. This is a reflection piece about my workshop experience focusing on data ethics of a tech worker like myself." />
<meta property="og:description" content="I participated a two-day workshop on tech ethics and policy at USF. The speakers and attendees were from a variety of disciplines ranging from tech to non-profit, law, and government. This is a reflection piece about my workshop experience focusing on data ethics of a tech worker like myself." />
<link rel="canonical" href="https://hongsups.github.io/blog/ethics/2020/01/30/cade-workshop-refelection.html" />
<meta property="og:url" content="https://hongsups.github.io/blog/ethics/2020/01/30/cade-workshop-refelection.html" />
<meta property="og:site_name" content="Asymptote" />
<meta property="og:image" content="https://hongsups.github.io/blog/images/2020-01-30-presentation.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-01-30T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://hongsups.github.io/blog/ethics/2020/01/30/cade-workshop-refelection.html","@type":"BlogPosting","headline":"Tech Policy Workshop and Data Ethics","dateModified":"2020-01-30T00:00:00-06:00","datePublished":"2020-01-30T00:00:00-06:00","image":"https://hongsups.github.io/blog/images/2020-01-30-presentation.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://hongsups.github.io/blog/ethics/2020/01/30/cade-workshop-refelection.html"},"description":"I participated a two-day workshop on tech ethics and policy at USF. The speakers and attendees were from a variety of disciplines ranging from tech to non-profit, law, and government. This is a reflection piece about my workshop experience focusing on data ethics of a tech worker like myself.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://hongsups.github.io/blog/feed.xml" title="Asymptote" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Asymptote</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Tech Policy Workshop and Data Ethics</h1><p class="page-description">I participated a two-day workshop on tech ethics and policy at USF. The speakers and attendees were from a variety of disciplines ranging from tech to non-profit, law, and government. This is a reflection piece about my workshop experience focusing on data ethics of a tech worker like myself.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-01-30T00:00:00-06:00" itemprop="datePublished">
        Jan 30, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      11 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#ethics">ethics</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><img src="/blog/images/2020-01-30-presentation.png" alt="" title="Photo of a presentation from the CADE Tech Policy Workshop in Nov 2019" /></p>

<p>As a data scientist working in industry, I frequently witness the impact a machine learning application can make. This impact often has a cascade of downstream effects which are inconceivable to a data scientist without enough domain knowledge. Nevertheless, under the widespread motto, “move fast and break things,” in tech industry, ML practitioners tend to care little about the size of their products’ impact. In certain cases, they even overlook scientifically rigorous evaluation of their products. These phenomena have been greatly worrying me ever since I started my career in industry. My concern has deepened due to many recent instances of AI applications reproducing human bias on a massive scale and aggravating existing socioeconomic problems.</p>

<p>Recently, I found out about the event, <strong><a href="https://www.sfdatainstitute.org/">The Tech Policy Workshop at the Center for Applied Data Ethics at USF</a></strong> via Dr. Rachel Thomas on social media, as I have been enjoying her blog posts and talks. She is smart, honest, and concerned about the welfare of people and society. Thus, I assumed that the workshop would be beneficial in many ways. The lineup was also very interesting because the speakers had diverse backgrounds. Additionally, the low registration cost was helpful.</p>

<p>I have been interested in <strong>fairness, accountability, and transparency of ML</strong> for several years, and thus have been attending events related to the topics. Compared with those events, I found this workshop unique in two ways. First, the organizers made a great effort to gather experts from a wide variety of domains ranging from computer science to policymaking. This makes sense because tech ethics and policy are multidisciplinary issues. Second, by choosing the format of a workshop, instead of a conference, the event was more interactive. There were several hands-on exercises, which encouraged valuable discussions among the attendees. The workshop exceeded my expectations and I felt grateful for the opportunity to attend.</p>

<h2 id="interactive-ethics-exercise-on-facial-recognition">Interactive ethics exercise on facial recognition</h2>

<p>Every session was interesting and unique in its own way. However, the main lesson I got out of the workshop came from the ethics session led by Irina Raicu from Santa Clara University. Ethics can be vague, abstract, and even esoteric but Irina made it sound accessible. She compared it to birdwatching; <strong>the more we learn about ethics, the more easily we can notice ethical issues in the world</strong>. Instead of giving a lengthy philosophy lecture, she taught us various easy-to-understand <strong>ethical “lenses”</strong>. She then asked us to use these in an exercise based on a real-world case about face recognition. <strong>The case was about a dataset<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> that ML researchers at IBM created to train a fairer face recognition model</strong>.</p>

<p>I was already familiar with the case. Joy Buolamwini, a ML researcher at MIT, published a study<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup> that revealed gender and racial bias in the training dataset in many commercial face recognition platforms including IBM’s. After this paper was published, IBM was forthcoming about the issue and they promised to improve their application. It is safe to assume that IBM researchers had good intentions when they published a new training dataset. Unfortunately, we found that this new dataset still had many problems, especially related to data privacy.</p>

<p>During the exercise, we applied different ethical lenses to address which ethical values were pursued or violated. Since we were a group of data scientists, policymakers, and activists, there were a variety of ideas. I admit that in the beginning of the exercise, I was somewhat frustrated because ethics cannot be easily optimized. This meant that we might not be able to reach conclusions easily. However, once we started discussion, I realized that the true value of the exercise was not about finding the right answer quickly, but about evaluating various perspectives especially when multiple ethical values were in conflict. The exercise also taught me that <strong>ethical decision making is a highly dynamic process that requires a diverse set of opinions</strong>. I started thinking this type of exercise would be beneficial for tech engineers to change the way they think.</p>

<h2 id="ethics-training-for-tech-workers">Ethics training for tech workers</h2>

<p>Granted, as Chris Riley at Mozilla pointed out during his session, teaching ethics to engineers may not be the best way to solve the tech-related problems in our society. After all, ethics focuses on individuals. Typically, <strong>socioeconomic problems are solved more effectively through legislation, regulations, and policies</strong>. However, several speakers hinted that training engineers to learn about ethical decision making can still be useful.</p>

<h2 id="tech-industry-has-great-power-and-influence-on-our-society">Tech industry has great power and influence on our society</h2>

<p>As Prof. Elizabeth E. Joh from UC Davis mentioned, <strong>tech industry has a significant amount of power</strong> these days. According to her, in certain circumstances, police must even drop their investigation so as not to violate the non-disclosure agreement related to the procurement of technological devices they use. She gave an example of police body-cams produced by the company, Axon, who dominates the market. They make almost every decision on how the device works, how and where data is stored and maintained, and so on. This means <strong>the management decision in the tech company can have a significant impact on the general public</strong>. Guillaume Chaslot from Algo Transparency delivered a similar message using an example from YouTube. It showed <strong>how slow and passive YouTube’s response was on content moderation</strong>. This is similar to Facebook’s naïve approach that contributed to the dissemination of disinformation over the internet, which created numerous sociopolitical problems all over the world.</p>

<h2 id="tech-workers-also-have-power">Tech workers also have power</h2>

<p>Multiple speakers emphasized that tech workers have great power as well. Recent tech employee walkouts demonstrate that power. Some even affected their companies’ decisions on certain social issues. The news<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup> about <strong>Google recently hiring firm known for anti-union efforts implies that companies now have recognized employee unrest as a threat</strong>. ML practitioners who work closely on sensitive datasets can wield even greater power. Kristian Lum from Human Rights Data Analyses Group shared a disturbing example of a ML application used at a government branch. A ML practitioner manipulated the results by hand-selecting model coefficients from multiple versions of a dataset, but this only came to light much later during an audit. Based on my conversations with other data scientists, <strong>proper oversight or formalized review of technical work is still missing in many industries</strong>. Under these circumstances, <strong>the responsibility to provide transparency and accountability falls to individual ML practitioners</strong>. Since building a ML application is a complex process, technical debt can aggravate quickly.</p>

<h2 id="what-i-can-do-as-a-tech-worker">What I can do as a tech worker</h2>

<p>The fact that ethics is about an individual’s decisions makes me think that there should be something I can do and that I should be aware of the responsibility that comes with my power as a tech worker. I can share a few things I try at work to make a change even though they are small. First, I seek out resources to <strong>learn about best practices in ML</strong> across the industry and to establish them at work regarding transparency and accountability. My team uses <strong>Model Cards<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">4</a></sup></strong>, which summarize how models are trained and how they are supposed to be used, and <strong>Datasheets<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">5</a></sup></strong>, which describe how data are collected, used, and processed. Second, to prevent technical debt, I often <strong>ask for reviews</strong> so that my work is seen by many different stakeholders. Another effort is <strong>bringing my work to a public space through publications, seminars, or conferences</strong>. For the tech ethics and policy issues, I try to <strong>take advantage of any opportunities inside my job (e.g., lunch-and-learn sessions) or outside (e.g., house parties or friends’ gatherings) to raise awareness</strong>. Finally, I try to learn more about the topics via events like this workshop.</p>

<h2 id="what-i-can-do-as-a-citizen">What I can do as a citizen</h2>

<p>I spent a lot of time thinking about what I can do as a tech worker, but I was forgetting something more important. At the end of the workshop, Prof. Elizabeth E. Joh talked about how tech companies wield their massive power in surveillance and policing. An attendee asked her whether there is anything we can do to make a change. Rather than answering his question, she asked him how many times he has previously attended city council meetings of his own city. She said there is still not enough awareness about this problem among the general public nor even momentum to create strong public opinion. That is why <strong>we need to raise our voices to address the issue and demand a change.</strong> Carrying out my duty as a citizen by speaking up was the one that I have overlooked.</p>

<p>At the workshop, I heard from Bay Area government officials about how they try to protect their citizens. Catherine Bracy from TechEquity Collaborative discussed organizations that help protect local communities from tech-related problems. Even though the Bay Area has been facing many problems such as housing and severe income inequality due to tech industry, it also has become the place where movements to fight back are pioneered. I think it has happened here because 1) it is the epicenter of the tech boom, 2) the severity of the problems is extreme, and 3) people are more aware of and sensitive about these issues.</p>

<p>Other local governments face a very different situation. The Litigating Algorithms report<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote">6</a></sup> by the AI Now Institute mentions that many local governments are drawn to the idea of implementing automated decision processes (ADP) because officials expect ADP to save money. <strong>Since the governments do not have affordable access to the right talent, they end up outsourcing the work to cheap vendors who often do poor execution and do not provide enough transparency.</strong> The report lists many examples of ADP that went wrong and harmed many people.</p>

<h2 id="responsibility-as-a-citizen-and-a-tech-worker">Responsibility as a citizen and a tech worker</h2>

<p>This workshop gave me an idea of how to <strong>combine my duty as a citizen and my duty as a tech worker.</strong> Government officials I spoke to at the workshop said it is extremely difficult for governments to catch up with the tech industry. It makes sense—policymaking is an inherently slow process but tech is all about fast developments and adaptations. To reduce the gap, <strong>we can start organizing small groups of tech workers to help nonprofits and local governments navigate the ever-changing tech space more efficiently</strong>. In the long run, these groups can form an advisory board or a civilian oversight committee to monitor tech-related issues in local communities such as predictive policing. By then, of course, these groups will include <strong>not only tech workers but other stakeholders such as local residents, legal experts, social scientists, activists, and more.</strong> This way, tech workers like myself can provide our local communities with technical expertise. At the same time, I will have a better idea of the real impact that my work makes. <strong>I optimistically believe that as we tech workers engage with our communities, we will change tech culture positively.</strong></p>

<h2 id="final-thoughts">Final thoughts</h2>

<p>In addition to learning much about tech ethics and policy, I found the workshop particularly special because I met great people from a variety of backgrounds, and I made new friends. I am sure many attendees had the same experience. It’s a rare occasion to have a diverse group of people sharing many concerns about the future in the same place for two days of honest discussions.</p>

<p>When I saw ads for the event, I hesitated whether I should register. I was unsure whether I would belong there because policy is outside of my experience. During the workshop, I confessed this to other attendees. Some said they had similar hesitations. After listening to my confession, Shirley Bekins, a housing activist who sat beside me, said with a big smile, “Of course you should be here!”</p>

<h2 id="references">References</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>M. Merler, N. Ratha, R. S. Feris, and J. R. Smith, “Diversity in Faces,” ArXiv190110436 Cs, Apr. 2019. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>J. Buolamwini and T. Gebru, “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classiﬁcation,” p. 15. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>N. Scheiber and D. Wakabayashi, “Google Hires Firm Known for Anti-Union Efforts,” New York Times, 20-Nov-2019. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>M. Mitchell et al., “Model Cards for Model Reporting,” Proc. Conf. Fairness Account. Transpar. – FAT 19, pp. 220–229, 2019. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>T. Gebru et al., “Datasheets for Datasets,” ArXiv180309010 Cs, Apr. 2019. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p>R. Richardson, J. M. Schultz, and V. M. Southerland, “LITIGATING ALGORITHMS 2019 US REPORT:,” p. 32. <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div><a class="u-url" href="/blog/ethics/2020/01/30/cade-workshop-refelection.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Machine learning and tech blog by Hongsup Shin</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/hongsups" title="hongsups"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/hongsupshin" title="hongsupshin"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/hongsupshin" title="hongsupshin"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
