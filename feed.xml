<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://hongsups.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hongsups.github.io/blog/" rel="alternate" type="text/html" /><updated>2021-03-09T16:41:44-06:00</updated><id>https://hongsups.github.io/blog/feed.xml</id><title type="html">Asymptote</title><subtitle>Machine learning and tech blog by Hongsup Shin</subtitle><entry><title type="html">FAccT Day 2. Automated Decision-Making, (Causal) Accountability, and Robustness</title><link href="https://hongsups.github.io/blog/conference/explainability/causality/robustness/responsible%20ai/ml/2021/03/09/facct-2021-main2.html" rel="alternate" type="text/html" title="FAccT Day 2. Automated Decision-Making, (Causal) Accountability, and Robustness" /><published>2021-03-09T00:00:00-06:00</published><updated>2021-03-09T00:00:00-06:00</updated><id>https://hongsups.github.io/blog/conference/explainability/causality/robustness/responsible%20ai/ml/2021/03/09/facct-2021-main2</id><author><name></name></author><category term="conference" /><category term="explainability" /><category term="causality" /><category term="robustness" /><category term="responsible AI" /><category term="ML" /><summary type="html">Keynote: In Praise of (Flawed) Mathematical Models</summary></entry><entry><title type="html">FAccT Day 1. AI Audit, Governance, and Trustworthiness</title><link href="https://hongsups.github.io/blog/conference/governance/explainability/responsible%20ai/ml/2021/03/08/facct-2021-main1.html" rel="alternate" type="text/html" title="FAccT Day 1. AI Audit, Governance, and Trustworthiness" /><published>2021-03-08T00:00:00-06:00</published><updated>2021-03-08T00:00:00-06:00</updated><id>https://hongsups.github.io/blog/conference/governance/explainability/responsible%20ai/ml/2021/03/08/facct-2021-main1</id><author><name></name></author><category term="conference" /><category term="governance" /><category term="explainability" /><category term="responsible AI" /><category term="ML" /><summary type="html">This year, for the first time, the FAccT conference has more than one track and there are 27 sessions (+80 talks) happening in 3 days. This is a summary of the first day of the main conference. My summary is based on the talks I attended based on my interest.</summary></entry><entry><title type="html">Notes on FAccT 2021 Tutorial Sessions</title><link href="https://hongsups.github.io/blog/conference/causality/fairness/explainability/responsible%20ai/ml/2021/03/04/facct-2021-tutorial.html" rel="alternate" type="text/html" title="Notes on FAccT 2021 Tutorial Sessions" /><published>2021-03-04T00:00:00-06:00</published><updated>2021-03-04T00:00:00-06:00</updated><id>https://hongsups.github.io/blog/conference/causality/fairness/explainability/responsible%20ai/ml/2021/03/04/facct-2021-tutorial</id><author><name></name></author><category term="conference" /><category term="causality" /><category term="fairness" /><category term="explainability" /><category term="responsible AI" /><category term="ML" /><summary type="html">Last year during the SciPy 2020 conference, I participated in a mentoring program and I’ve got to know a fellow data scientist, Henrik Hain. He diligently uploaded a daily update during the conference, which was impressive. Inspired by him, I’ve decided to follow his practice and to write notes during my attendance in the FAccT 2021 this year.</summary></entry><entry><title type="html">Markdown and GitHub for Scientific Writing</title><link href="https://hongsups.github.io/blog/collaboration/2020/11/24/github-manuscript-review.html" rel="alternate" type="text/html" title="Markdown and GitHub for Scientific Writing" /><published>2020-11-24T00:00:00-06:00</published><updated>2020-11-24T00:00:00-06:00</updated><id>https://hongsups.github.io/blog/collaboration/2020/11/24/github-manuscript-review</id><author><name></name></author><category term="collaboration" /><summary type="html">Last year, I was fortunate to have an opportunity to do a poster presentation at the Scientific Computing in Python (SciPy) conference. Every presenter has an option to submit a written proceedings and I decided to participate. I’ve never had a chance to present my ML work as a paper in industry, and so I thought it would be a good experience.</summary></entry><entry><title type="html">Efficient Bug Discovery with Machine Learning for Hardware Verification</title><link href="https://hongsups.github.io/blog/ml/verification/2020/09/22/arm-rsh-blog-verification.html" rel="alternate" type="text/html" title="Efficient Bug Discovery with Machine Learning for Hardware Verification" /><published>2020-09-22T00:00:00-05:00</published><updated>2020-09-22T00:00:00-05:00</updated><id>https://hongsups.github.io/blog/ml/verification/2020/09/22/arm-rsh-blog-verification</id><author><name></name></author><category term="ML" /><category term="verification" /><summary type="html">Imagine designing a highly complex machine. In order to be certain that it functions as its design specifies and does not have any bugs, you would need to test every aspect of the design exhaustively. If the machine is controlled by a set of knobs that can be turned on and off, this verification process can get exponentially complex. For instance, with a machine that has 100 binary on-off knobs, then 2100 tests need to be run to cover all possible combinations. If we assume that a single test takes one second to run, this equates to 1022 years of testing. For present-day microprocessors, it is even more challenging. There can be thousands or tens of thousands of two-state flip-flops in a single microprocessor. Therefore, it is impossible to verify microprocessor designs exhaustively.</summary></entry></feed>